{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Group plot algorithm — methods reference\n",
        "\n",
        "This notebook is a **standalone narrative description** of the algorithm used for the Grouped plot type. It reproduces the exact logic in `group_plot.py` using pandas and numpy only. The pipeline:\n",
        "\n",
        "1. **Pre-filter** the master (raw) dataframe by column selections.\n",
        "2. **Extract the y column** with optional transformations (numeric coerce, optional absolute value, optional remove-values filter).\n",
        "3. **Group by a group column** and compute the chosen y-stat (e.g. mean) per group.\n",
        "4. **Full stats table**: for one group column and one y column, compute count, min, max, mean, std, sem, and CV per group.\n",
        "\n",
        "All intermediate results are printed so you can follow the algorithm step by step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Imports, path to the example CSV, and algorithm parameters. The notebook expects to be run with the current working directory set to the **nicewidgets project root** (the directory containing `data/` and `notebooks/`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Any, Optional\n",
        "\n",
        "# Path to example data (run from nicewidgets project root)\n",
        "DATA_DIR = Path(\"data\")\n",
        "if not (DATA_DIR / \"kym_event_report.csv\").exists():\n",
        "    DATA_DIR = Path(\"../data\")\n",
        "CSV_PATH = DATA_DIR / \"kym_event_report.csv\"\n",
        "assert CSV_PATH.exists(), f\"Example CSV not found: {CSV_PATH}\"\n",
        "\n",
        "# Sentinel for \"no filter\" (matches group_plot.PRE_FILTER_NONE)\n",
        "PRE_FILTER_NONE = \"(none)\"\n",
        "\n",
        "# Algorithm parameters (same as group_plot.py __main__)\n",
        "PRE_FILTER_COLUMNS = [\"roi_id\"]\n",
        "UNIQUE_ROW_ID_COL = \"kym_event_id\"\n",
        "PRE_FILTER = {\"roi_id\": PRE_FILTER_NONE}  # no filter = use all rows\n",
        "GROUP_COL = \"event_type\"\n",
        "YCOL = \"score_peak\"\n",
        "YSTAT = \"mean\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Algorithm functions (from group_plot.py)\n",
        "\n",
        "The following cells define the same functions as in `group_plot.py`, so this notebook is self-contained and does not require importing the package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Pre-filter\n",
        "\n",
        "Filter the master dataframe by pre-filter column selections. For each column in `pre_filter_columns`, if the selection is not `PRE_FILTER_NONE`, keep only rows where `df[col].astype(str) == str(selection)`. Selections are ANDed across columns. Rows with missing `unique_row_id_col` are then dropped. (Same logic as `DataFrameProcessor.filter_by_pre_filters()`.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_by_pre_filters(\n",
        "    df: pd.DataFrame,\n",
        "    pre_filter_columns: list[str],\n",
        "    selections: dict[str, Any],\n",
        "    unique_row_id_col: str,\n",
        ") -> pd.DataFrame:\n",
        "    df_f = df.copy()\n",
        "    for col in pre_filter_columns:\n",
        "        val = selections.get(col, PRE_FILTER_NONE)\n",
        "        if val is None or val == PRE_FILTER_NONE:\n",
        "            continue\n",
        "        df_f = df_f[df_f[col].astype(str) == str(val)]\n",
        "    df_f = df_f.dropna(subset=[unique_row_id_col])\n",
        "    return df_f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Extract y values\n",
        "\n",
        "Get the y column as a numeric series. Converts to numeric (coerce errors to NaN), optionally applies `abs()`, and optionally sets values outside `[-threshold, +threshold]` to NaN. (Same logic as `DataFrameProcessor.get_y_values()`.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_y_values(\n",
        "    df_f: pd.DataFrame,\n",
        "    ycol: str,\n",
        "    use_absolute: bool = False,\n",
        "    use_remove_values: bool = False,\n",
        "    remove_values_threshold: Optional[float] = None,\n",
        ") -> pd.Series:\n",
        "    y = pd.to_numeric(df_f[ycol], errors=\"coerce\")\n",
        "    if use_absolute:\n",
        "        y = y.abs()\n",
        "    if use_remove_values and remove_values_threshold is not None:\n",
        "        y[(y < -remove_values_threshold) | (y > remove_values_threshold)] = np.nan\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Group and aggregate (single stat)\n",
        "\n",
        "Compute the aggregated stat per group: build a temporary frame with columns `[group, y]`, then group by `group` and apply the chosen y-stat (e.g. mean, count, std, sem, cv). Returns a Series with index = group labels, values = aggregated y. (Same logic as `_figure_grouped()`.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def grouped_aggregate(\n",
        "    df_f: pd.DataFrame,\n",
        "    group_col: str,\n",
        "    ycol: str,\n",
        "    ystat: str,\n",
        "    use_absolute: bool = False,\n",
        "    use_remove_values: bool = False,\n",
        "    remove_values_threshold: Optional[float] = None,\n",
        "    cv_epsilon: float = 1e-10,\n",
        ") -> pd.Series:\n",
        "    g = df_f[group_col].astype(str)\n",
        "    y = get_y_values(df_f, ycol, use_absolute=use_absolute,\n",
        "                     use_remove_values=use_remove_values,\n",
        "                     remove_values_threshold=remove_values_threshold)\n",
        "    tmp = pd.DataFrame({\"group\": g, \"y\": y}).dropna(subset=[\"group\"])\n",
        "    if ystat == \"count\":\n",
        "        return tmp.groupby(\"group\", dropna=False)[\"y\"].count()\n",
        "    tmp[\"y\"] = pd.to_numeric(tmp[\"y\"], errors=\"coerce\")\n",
        "    if ystat == \"cv\":\n",
        "        grp = tmp.groupby(\"group\", dropna=False)[\"y\"]\n",
        "        mean_ = grp.mean()\n",
        "        std_ = grp.std(ddof=1)\n",
        "        cv = std_ / mean_\n",
        "        return cv.where(np.abs(mean_) >= cv_epsilon, np.nan)\n",
        "    if ystat == \"sem\":\n",
        "        return tmp.groupby(\"group\", dropna=False)[\"y\"].sem(ddof=1)\n",
        "    return getattr(tmp.groupby(\"group\", dropna=False)[\"y\"], ystat)()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Full stats table\n",
        "\n",
        "For one group column and one y column, compute a full stats table per group: **count, min, max, mean, std, sem, CV**. Same preprocessing as `get_y_values`. std and sem use `ddof=1`; CV = std/mean with NaN when |mean| < cv_epsilon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def grouped_full_stats_table(\n",
        "    df_f: pd.DataFrame,\n",
        "    group_col: str,\n",
        "    ycol: str,\n",
        "    use_absolute: bool = False,\n",
        "    use_remove_values: bool = False,\n",
        "    remove_values_threshold: Optional[float] = None,\n",
        "    cv_epsilon: float = 1e-10,\n",
        ") -> pd.DataFrame:\n",
        "    g = df_f[group_col].astype(str)\n",
        "    y = get_y_values(df_f, ycol, use_absolute=use_absolute,\n",
        "                     use_remove_values=use_remove_values,\n",
        "                     remove_values_threshold=remove_values_threshold)\n",
        "    tmp = pd.DataFrame({\"group\": g, \"y\": y}).dropna(subset=[\"group\"])\n",
        "    tmp[\"y\"] = pd.to_numeric(tmp[\"y\"], errors=\"coerce\")\n",
        "    grp = tmp.groupby(\"group\", dropna=False)[\"y\"]\n",
        "    count = grp.count()\n",
        "    min_ = grp.min()\n",
        "    max_ = grp.max()\n",
        "    mean_ = grp.mean()\n",
        "    std_ = grp.std(ddof=1)\n",
        "    sem_ = grp.sem(ddof=1)\n",
        "    cv_ = (std_ / mean_).where(np.abs(mean_) >= cv_epsilon, np.nan)\n",
        "    return pd.DataFrame({\"count\": count, \"min\": min_, \"max\": max_, \"mean\": mean_, \"std\": std_, \"sem\": sem_, \"cv\": cv_})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 0: Master dataframe (raw)\n",
        "\n",
        "Load the CSV and optionally add a unique row ID column if the schema expects it (e.g. for radon_report_db). Below we show shape and the first rows of the columns used later (group column, y column, unique row ID)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_master = pd.read_csv(CSV_PATH)\n",
        "if UNIQUE_ROW_ID_COL not in df_master.columns and \"path\" in df_master.columns and \"roi_id\" in df_master.columns:\n",
        "    df_master[UNIQUE_ROW_ID_COL] = df_master[\"path\"].astype(str) + \"|\" + df_master[\"roi_id\"].astype(str)\n",
        "\n",
        "print(\"--- Step 0: Master dataframe (raw) ---\")\n",
        "print(f\"Shape: {df_master.shape}\")\n",
        "cols = [c for c in [GROUP_COL, YCOL, UNIQUE_ROW_ID_COL] if c in df_master.columns]\n",
        "print(df_master[cols].head(10).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: After pre-filter\n",
        "\n",
        "Apply the pre-filter: restrict rows by the selected values for each pre-filter column (here we use no filter), then drop rows with missing unique row ID. Below: shape and first rows of the key columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_f = filter_by_pre_filters(df_master, PRE_FILTER_COLUMNS, PRE_FILTER, UNIQUE_ROW_ID_COL)\n",
        "\n",
        "print(\"--- Step 1: After pre-filter ---\")\n",
        "print(f\"Shape: {df_f.shape}\")\n",
        "cols = [c for c in [GROUP_COL, YCOL, UNIQUE_ROW_ID_COL] if c in df_f.columns]\n",
        "print(df_f[cols].head(20).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Y values (raw column + computed series)\n",
        "\n",
        "Extract the y column as a numeric series (coerce to numeric, optional abs/remove-values not used here). Display: raw column, and the computed series used in the rest of the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_series = get_y_values(df_f, YCOL)\n",
        "step2_display = pd.DataFrame({\n",
        "    GROUP_COL: df_f[GROUP_COL].values,\n",
        "    YCOL: df_f[YCOL].values,\n",
        "    \"y (computed)\": y_series.values,\n",
        "})\n",
        "print(\"--- Step 2: Y values (raw column + computed series) ---\")\n",
        "print(step2_display.head(20).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Per-row (group, y) before aggregation\n",
        "\n",
        "Build the temporary frame used inside the aggregation: one row per data row, columns `group` (from group column as string) and `y` (numeric). Rows with missing group are dropped. This is the input to the groupby that produces the single-stat result and the full stats table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g = df_f[GROUP_COL].astype(str)\n",
        "tmp_display = pd.DataFrame({\"group\": g, \"y\": y_series}).dropna(subset=[\"group\"])\n",
        "tmp_display[\"y\"] = pd.to_numeric(tmp_display[\"y\"], errors=\"coerce\")\n",
        "print(\"--- Step 3: Per-row (group, y) before aggregation ---\")\n",
        "print(tmp_display.head(20).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final grouped plot data (single stat)\n",
        "\n",
        "Run the full pipeline: pre-filter → grouped aggregation with the chosen y-stat (e.g. mean). The result is one value per group, used for the grouped plot (x = group, y = value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agg = grouped_aggregate(df_f, group_col=GROUP_COL, ycol=YCOL, ystat=YSTAT)\n",
        "result_table = pd.DataFrame({\"group\": agg.index.astype(str), \"value\": agg.values})\n",
        "\n",
        "print(\"--- Final grouped plot data ---\")\n",
        "print(f\"Parameters used: group_col = {GROUP_COL!r}, ycol = {YCOL!r}, ystat = {YSTAT!r}\")\n",
        "print(\"Table (x = group, y = value):\")\n",
        "print(result_table.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Full stats table\n",
        "\n",
        "For the same group column and y column, compute all summary statistics per group: **count, min, max, mean, std, sem, CV**. This is the final methods output: one row per group, one column per stat.\n",
        "\n",
        "Below we also print a **bulleted list of the filtering** that was applied to the master dataframe before this analysis (e.g. roi_id, etc.), so the full stats table is fully specified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Filtering applied to the master dataframe (before analysis):\")\n",
        "for col in PRE_FILTER_COLUMNS:\n",
        "    val = PRE_FILTER.get(col, PRE_FILTER_NONE)\n",
        "    if val is None or val == PRE_FILTER_NONE:\n",
        "        print(f\"  - {col}: (none) [no filter]\")\n",
        "    else:\n",
        "        print(f\"  - {col}: {val}\")\n",
        "print()\n",
        "\n",
        "full_stats = grouped_full_stats_table(df_f, group_col=GROUP_COL, ycol=YCOL)\n",
        "print(\"--- Full stats table (group_col = {0!r}, ycol = {1!r}) ---\".format(GROUP_COL, YCOL))\n",
        "print(full_stats.to_string())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
